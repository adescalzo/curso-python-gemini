# Lección 12.4: Creando una Conversación

## Objetivo

Mejorar nuestro chatbot para que pueda recordar el contexto de la conversación, permitiendo un diálogo más natural.

---

## Contenido Principal

Para que un LLM "recuerde" una conversación, debemos enviarle el historial de preguntas y respuestas anteriores junto con la nueva pregunta. La librería de Google simplifica enormemente este proceso con el objeto `ChatSession`.

### El Objeto `ChatSession`

En lugar de llamar a `model.generate_content()` en cada turno, primero iniciamos una sesión de chat con `model.start_chat()`.

```python
# Inicia una sesión de chat con un historial vacío
chat = model.start_chat(history=[])
```

Este objeto `chat` mantendrá automáticamente el historial de la conversación.

### Enviando Mensajes en una Sesión

Una vez que tenemos la sesión, en lugar de `generate_content()`, usamos el método `chat.send_message()`.

```python
response = chat.send_message("¿Cuál es la capital de Francia?")
print(response.text) # Imprime "París"

# La librería ya ha guardado la pregunta y la respuesta en el historial.
# Ahora podemos hacer una pregunta contextual.
response = chat.send_message("¿Y cuál es su población?")
print(response.text) # Ahora el modelo sabe que "su" se refiere a París.
```

El método `send_message` hace dos cosas:

1. Envía el nuevo prompt junto con todo el historial anterior a la API.
2. Recibe la respuesta y la añade también al historial para futuras llamadas.

### Ejemplo Práctico

El archivo `ejemplos/12.4_1_chat_conversacional.py` modifica el chatbot anterior para usar `start_chat` y `send_message`, dándole memoria y contexto.
